<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://lurenss.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://lurenss.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-04-19T06:42:54+00:00</updated><id>https://lurenss.github.io/feed.xml</id><title type="html">blank</title><subtitle>:)</subtitle><entry><title type="html">Why we need next generation of scrapers and it’s more serious than you think</title><link href="https://lurenss.github.io/blog/2024/We-need-next-generation-scrapers/" rel="alternate" type="text/html" title="Why we need next generation of scrapers and it’s more serious than you think"/><published>2024-04-15T22:40:00+00:00</published><updated>2024-04-15T22:40:00+00:00</updated><id>https://lurenss.github.io/blog/2024/We-need-next-generation-scrapers</id><content type="html" xml:base="https://lurenss.github.io/blog/2024/We-need-next-generation-scrapers/"><![CDATA[<p>It’s from at least a decade that we hear data is the new oil, and it’s true, data is the new oil, but the problem is that the oil is not in the ground, it’s in the web, and the way to extract it is not with a drill but with a scraper. Yes but why the data are so valuable? <br/> Data in this decade gained value thanks to explosion of data analytics sector, and this was the firs wave, another wave is coming, the AI wave, with the advent of transformers and subsequently LLMs, that need an enormous amount of data to be trained on. All the big tech and non-tech companies are launching themselves in this direction, smelling huge profits and striving for supremacy by trying to get to the coveted AGI here a two image to compare these two waves. <br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/small_wave-480.webp 480w, /assets/img/small_wave-800.webp 800w, /assets/img/small_wave-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/small_wave.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/giant_wave-480.webp 480w, /assets/img/giant_wave-800.webp 800w, /assets/img/giant_wave-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/giant_wave.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Small wave of data analytics on the left, big wave of AI on the right </div> <p>Let’s going back to the metaphor of the oil, during this century we have passed from the rusty land drill to the modern oil rig that can extract oil from the sea, and this is what we need to do with the scrapers, because the web is not a single site, it’s a “sea” of sites, and we need to extract data from most of them respecting the rules obviously, and this is not an easy task, because the web is not a static place, the scrapers need to be able to adapt to this dynamism, currently they are not able, and this is the challenge that we need to face in the next years, and this is the first point on why we need the next generation of scrapers.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/rusty_drill-480.webp 480w, /assets/img/rusty_drill-800.webp 800w, /assets/img/rusty_drill-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/rusty_drill.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/modern_drill-480.webp 480w, /assets/img/modern_drill-800.webp 800w, /assets/img/modern_drill-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/modern_drill.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>There is another point that we need to consider, we need to avoid at all cost the oligopoly of the big tech companies in the AI field. And to do that we need to democratize the access to the data in order to allow the small startups and the open source community to compete with the big tech companies, and one key point to do that is to have tons of data acquired with smart scrapers and small amout of money. One might think at this point, here he is, another tech-guy against capitalism in a random way, sorry dude, but this time you got it wrong. The problem is that large language models (LLMs) are so powerful tool that can be used at work in many fields and also as decision making support tool having a strong influence on the users. The ability to tune the model from arbitrary people to a specific tendency can be a powerful weapon convoing some kind of information to the public that can be used to manipulate the public opinion since in the future the usage trend of this tool is going to increase dramatically please let’s avoid what is happening with the social media, where the big tech companies are the only one that have the power to control the information and they aren’t able to deal with misinformation causing a lot of problems that we are seeing in the nowadays society. <br/></p> <p>Since i believe in what i’m saying and my life randomly brought me to deal with data, i decided to do something about it, and i’m working on a project with other people that aims to democratize the access to the data, this is ScrapegraphAI, an Open Source Python library that aims to be in the next generation of scrapers, and we are working hard to make it happen, if you want to know more about it, please visit repo on <a href="https://github.com/VinciGit00/Scrapegraph-ai">github</a> and if you want to contribute, you are welcome.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/scrapegraphai_logo-480.webp 480w, /assets/img/scrapegraphai_logo-800.webp 800w, /assets/img/scrapegraphai_logo-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/scrapegraphai_logo.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> ScrapegraphAI logo </div> <p>P.S maybe a more technical post about the project will come in the future, stay tuned :)))))</p>]]></content><author><name></name></author><category term="post"/><category term="scraping"/><category term="AI"/><category term="breakthrough"/><category term="LLMs"/><summary type="html"><![CDATA[It’s from at least a decade that we hear data is the new oil, and it’s true, data is the new oil, but the problem is that the oil is not in the ground, it’s in the web, and the way to extract it is not with a drill but with a scraper. Yes but why the data are so valuable? Data in this decade gained value thanks to explosion of data analytics sector, and this was the firs wave, another wave is coming, the AI wave, with the advent of transformers and subsequently LLMs, that need an enormous amount of data to be trained on. All the big tech and non-tech companies are launching themselves in this direction, smelling huge profits and striving for supremacy by trying to get to the coveted AGI here a two image to compare these two waves. Small wave of data analytics on the left, big wave of AI on the right Let’s going back to the metaphor of the oil, during this century we have passed from the rusty land drill to the modern oil rig that can extract oil from the sea, and this is what we need to do with the scrapers, because the web is not a single site, it’s a “sea” of sites, and we need to extract data from most of them respecting the rules obviously, and this is not an easy task, because the web is not a static place, the scrapers need to be able to adapt to this dynamism, currently they are not able, and this is the challenge that we need to face in the next years, and this is the first point on why we need the next generation of scrapers.]]></summary></entry><entry><title type="html">Beyond chatbots</title><link href="https://lurenss.github.io/blog/2024/More-than-chatbots/" rel="alternate" type="text/html" title="Beyond chatbots"/><published>2024-01-14T21:01:00+00:00</published><updated>2024-01-14T21:01:00+00:00</updated><id>https://lurenss.github.io/blog/2024/More-than-chatbots</id><content type="html" xml:base="https://lurenss.github.io/blog/2024/More-than-chatbots/"><![CDATA[<p>Even the least tech-savvy person can see that something significant has occurred in the last year, the release of ChatGPT on 30-12-2022 to the public and the consequent mass usage is likely to pass from a small fraction of people that play a video game like tetris to the millions of people that play a more advanced videgame like GTA 6 (hopefully in 2025 if Rockstar doesn’t make treats :) ) The only difference is the gaming field this took more than 30 years, in the AI field was a lightning strike.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/tris-480.webp 480w, /assets/img/tris-800.webp 800w, /assets/img/tris-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/tris.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/gta6-480.webp 480w, /assets/img/gta6-800.webp 800w, /assets/img/gta6-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/gta6.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Tris on the left, GTA 6 on the right, the gap is huge </div> <p>As a consequence of this,the AI field boiled up once again, and a new gold rush started. It’s important to mention that not only big corporations are involved in this, but also small startups and even single developers of the open source community, fortunatly i say, It’s important to avoid the monopoly of big corporations in this field, but this will be maybe topic for another post.</p> <h2 id="how-this-stuff-works-on-high-level">How this stuff works on high level</h2> <p>The underlying technology that powers up LLMs is called Transformers, it was invented by Google in 2017 (here the <a href="[https://arxiv.org/abs/1706.03762]">link</a> for the paper) <br/> In order to understand let’s assume that our training set is only a single phrase with the following words “I like eat pizza with Marco” and not the entire wikipedia, reddit as did OpenAI. So basically what does a transformer is given a sequence of word guess the next one, that’s it. <br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/transformer1-480.webp 480w, /assets/img/transformer1-800.webp 800w, /assets/img/transformer1-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/transformer1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>At the beginning the transformer it doesn’t know anything so it decide to put a random word.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/transformer2-480.webp 480w, /assets/img/transformer2-800.webp 800w, /assets/img/transformer2-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/transformer2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>At this point the learning algorithm say to the transformer, Hey jackass you don’t have to insert toilet after I like eat but pizza. So the next time when I ask what is the word that comes after I like eat it will answer with pizza.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/transformer3-480.webp 480w, /assets/img/transformer3-800.webp 800w, /assets/img/transformer3-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/transformer3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>So now this new sequence becomes the input of the transformer and it has to guess the next word, so the previous process is iterated and so on.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/transformer4-480.webp 480w, /assets/img/transformer4-800.webp 800w, /assets/img/transformer4-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/transformer4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>This is just what does the transform predict the next word, or in Natural Language Processing terms predict the next token, just it. More text see the transformer and more will be able to produce sophisticated text given a certain sequence.</p> <h2 id="beyond-the-text">Beyond the text</h2> <p>Until now we have seen how the transformer can be used to generate text, but what if we want to use it for something else? <br/> Well It’s simple instead of using word as tokens we can use different things like GPS coordinates, DNA sequences and so on. Let’s take Transportation field where the ability to forecast people trajectories can greatly improve the efficiency and effectiveness of transportation systems. With the availability of a vast dataset of GPS coordinates, the transformer model can be utilized to predict the next GPS coordinate of an individual or group of people based on a sequence of previous coordinates. This advanced predictive capability has the potential to optimize transportation routes, reduce travel time, and enhance overall user experience. Alternatively, this technique can also be used to produce synthetic data in instances where it is necessary to achieve a specific population size and analyze its characteristics, based on a representative dataset. Creating another parallelism between videogames and real life, with a transformer based model trained on user GPS coordinates, is tool that is mimicking the actions and behaviors of individuals based on their history, similar to how city builders or management games function, when the player is aware of traffic congestion, He can take the necessary steps to avoid it, like insert a new road or a new bus line.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/citiesskylin-480.webp 480w, /assets/img/citiesskylin-800.webp 800w, /assets/img/citiesskylin-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/citiesskylin.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A screenshot from Cities Skylines, a city builder game </div> <p>What I’m saying is not just something I dreamed up - there are people who are working on it and have shown preliminary results, like in this papers <a href="[(https://www.frontiersin.org/articles/10.3389/fphy.2022.1021176/full)]">Generation of individual daily trajectories by GPT-2</a> and <a href="[(https://arxiv.org/pdf/2308.07940.pdf)]">Generating Individual Trajectories Using GPT-2 Trained from Scratch on Encoded Spatiotemporal Data</a>. Instead for DNA sequences there are a lot of applications, for example, we can use it to predict the next nucleotide in a sequence, or to predict the next amino acid in a protein sequence, or to predict the next codon in a DNA sequence. So it is useful for task like sequence analysis, gene expression, here a paper that cover how transformers can be used in this field <a href="[(https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad001/6984737)]">Transformer-based models for gene expression prediction</a>.</p> <p>In conclusion, the transformer architecture has revolutionized the field of NLP, allowing for the creation of LLMs with the ability to simulate human-like conversation. Through the use of transformers, language models can be trained on vast datasets, allowing for the prediction of the next word or token based on a sequence of previous words. However, the applications of transformers extend beyond chatbots and language generation. Its ability to process and predict various forms of data, such as GPS coordinates and DNA sequences, opens up a world of possibilities in different fields. While there is still much to explore and develop in this area, the potential for transformers is evident and one technology has a great impact in various and different fields it’s for sure a sign of that is and it will be more and more important in the future.</p>]]></content><author><name></name></author><category term="post"/><category term="transformers"/><category term="AI"/><category term="breakthrough"/><category term="chatbots"/><summary type="html"><![CDATA[Transformers the AI breakthrough]]></summary></entry></feed>